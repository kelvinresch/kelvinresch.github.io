<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Fast Robots Spring 2025 - Kelvin Resch</title>
    <!-- Favicon-->
    <link rel="icon" type="image/x-icon" href="assets/robot.ico" />
    <!-- Bootstrap icons-->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.1/font/bootstrap-icons.css" rel="stylesheet" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
    <!-- Prism.js CSS for Syntax Highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
</head>

<body>
    <!-- Prism.js JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.js"></script>
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>  -->
    <!-- Responsive navbar-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-danger">
        <div class="container px-lg-5">
            <a class="navbar-brand" href="https://kelvinresch.github.io">Lab 12</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false"
                aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav ms-auto mb-2 mb-lg-0">
                    <li class="nav-item"><a class="nav-link active" aria-current="page"
                            href="https://kelvinresch.github.io">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="https://www.linkedin.com/in/kelvin-resch">Contact</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Header-->
    <header class="py-5">
        <div class="container px-lg-5">
            <div class="p-4 p-lg-5 bg-light rounded-3 text-center">
                <div class="m-4 m-lg-5">
                    <h1 class="display-5 fw-bold">Lab 12</h1>
                    <p class="fs-4">Path Planning and Execution</p>
                </div>
            </div>
        </div>
    </header>

    <!-- Page Content-->
    <section class="pt-4">
        <div class="container px-lg-5">
            <!-- Single Bootstrap Card -->
            <div class="card bg-light border-0">
                <div class="card-body p-4 p-lg-5">
                    <!-- Card Content -->
                    <h1 class="card-title text-center mb-4">Introduction</h1>
                    <p class="card-text">
                        The purpose of this class was to built a robotic,
                        autonomous car that could navigate its
                        surroundings. This required us to contend with
                        various sensors, non-linearities, feedback
                        control, and embedded programming. The goal of
                        this lab was to implement navigation through
                        a room with our car. We started with building the
                        robot's hardware: sensors, motors, and wiring.
                        Then, we implemented the software: PID loops to
                        control orientation and linear position, a Kalman
                        Filter to merge sensor data, and Bayes filtering
                        to localize the robot in a room. Finally, it's
                        time to put all of this together and let the robot
                        navigate itself through the room.
                    </p>
                    <h1 class="card-title text-center mb-4">Key Parts</h1>
                    <p class="card-text">
                        The system in composed of three main parts:
                    </p>
                    <p class="card-text">
                        State machine to step through the different phases of
                        the robot's movement, angular PID control to
                        rotate the robot to a setpoint, and linear PID control
                        to move the robot precise distances.
                    </p>
                    <p class="card-text">
                        For the PID control, I wrote a small library to reduce
                        the spaghetti code that I wrote in previous labs.
                        This consisted of a PID class that would be initialized
                        with control parameters, and a method to
                        compute the control signal. The class also has a method
                        to reset the internal state of the PID controller.
                    </p>
                    <div class="text-center mb-4">
                        <img src="assets/Lab12/12_1.png" alt="Lab11_1" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        Here's the core method of the PID class. It takes the
                        setpoint, sensor, and time as inputs, and returns
                        the control signal. I included clamping on the integral
                        term to prevent windup, and I also included
                        a lowpass filter on the derivative term to reduce noise.
                        The low pass filter is implemented as a simple
                        first order filter, and the cutoff frequency is adjustable
                        based on the initalization of the PID class..
                    </p>
                    <div class="text-center mb-4">
                        <img src="assets/Lab12/12_2.png" alt="Lab11_1" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <h1 class="card-title text-center mb-4">Challenges</h1>
                    <p class="card-text">
                        The biggest challenge I faced in this lab was hardware and spaghettification.
                        I spent some time in the beginning of the semester to build a high quality robot, and
                        everything held up very well up until this lab. For some reason, but motor controllers
                        became unresponsive, and I had to use Rachel Arena's car to complete the lab.
                    </p>
                    <p class="card-text">
                        The other challenge I faced in this lab was spaghetti code. Up until this point, everything
                        I wrote was in one big file, and much of my code approached 1500 lines. This made the code
                        difficult to read and maintain, especially because there were sections that were repeated.
                        One of the things I did to reduce the spaghetti code was to write a PID class that would
                        handle the PID control for me. This is because PID control is used in two places in this
                        program, but the execution is the exact same. It just has different parameters.
                    </p>
                    <p class="card-text">
                        (-3 ft, -2 ft, 0 deg)
                    </p>
                    <p class="card-text">
                        (0 ft, 3 ft, 0 deg)
                    </p>
                    <p class="card-text">
                        (5 ft, -3 ft, 0 deg)
                    </p>
                    <p class="card-text">
                        (5 ft, 3 ft, 0 deg)
                    </p>
                    <p class="card-text">
                        After running a localization step at each of these locations, the estimated position will be
                        marked
                        in blue on the "Trajectory Plotter" provided by the course staff. We will then compare the
                        estimated
                        position to the ground truth position in green.
                    </p>
                    <h1 class="card-title text-center mb-4">Implementation</h1>
                    <p class="card-text">
                        The only thing that the robot is doing here is rotating and collecting data. The actual
                        localization
                        is done on my PC, so I need to set up data collection so that I can do the compute in my python
                        notebooks.
                    </p>
                    <h2 class="card-title text-center mb-4">perform_observation_loop()</h2>
                    <p class="card-text">
                        To collect the data, I wrote perform_observation_loop(), which would call COLLECT_DATA on the
                        robot,
                        which would trigger it to rotate 360 degrees and collect 18 data points (20 degrees apart) from
                        the
                        ToF sensors, and send that data back to my PC.
                    </p>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_2.png" alt="Lab11_2" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        The method relies on three numpy arrays: times, distances, and angles. These arrays are
                        populated by
                        the notification handler which parses the collected data from the robot:
                    </p>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_3.png" alt="Lab11_3" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        Together, these three arrays report the data required by a single localization step on the
                        robot.
                    </p>
                    <h1 class="card-title text-center mb-4">Localization results</h1>
                    <p class="card-text">
                        Here are the results of running a single localization step at each position:
                    </p>
                    <h2 class="card-title text-center mb-4">Localization results</h2>
                    <h3 class="card-title text-center mb-4">Position (-3, -2)</h3>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_4.png" alt="Lab11_4" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        Overall localization worked exceedingly well, and out of all four points, I think this one was
                        the easiest to localize. This is because the position (-3, -2) is equidistant from the far,
                        near,
                        and left walls, so any sensor bias cancels out. This is reflected in the result, as the green
                        belief
                        dot is centered in the section of the room.
                    </p>
                    <h3 class="card-title text-center mb-4">Position (0, 3)</h3>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_5.png" alt="Lab11_5" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        I think this point was the most succeptible to sensor bias, especially because the ToF sensor
                        has
                        a tendency to underestimate the distance to the wall when the wall is close. I showed this all
                        the
                        way back in Lab 3, and this bias is affecting my belief by pushing it closer to the top wall
                        than
                        it should be. Overall though, localization worked fairly well.
                    </p>
                    <h3 class="card-title text-center mb-4">Position (5, -3)</h3>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_6.png" alt="Lab11_6" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        This position was the best out of the few times that I tried localizing, but it was off the
                        green
                        dot the other times I tried collecting data. I think this is because the features the robot was
                        detecting
                        were a little more complex this time, with the hallway above and the open space to the upper
                        left.
                        Errors in angle estimation would also affect the localization result significantly, which is why
                        I
                        think this position was so variable.
                    </p>
                    <h3 class="card-title text-center mb-4">Position (5, 3)</h3>
                    <div class="text-center mb-4">
                        <img src="assets/Lab11/11_7.png" alt="Lab11_7" class="img-fluid rounded-3"
                            style="max-width: 100%; height: auto;">
                    </div>
                    <p class="card-text">
                        Similar to the last position, this position also had some variability, although this one wasn't
                        as bad.
                        I think I did 4 runs of localization at this position, and the robot localized correctly twice.
                        The
                        features here aren't as complex as (5, -3), and it's also closer to stuff, which means angle
                        doesn't
                        matter as much, which is why this result was more consistent.
                    </p>
                    <h2 class="card-title text-center mb-4">Conclusion</h2>
                    <p class="card-text">
                        I think in my specific case, I used a PD controller to rotate my robot to angle setpoints, but
                        there
                        was a lot of hysteresis in my robot. Sometimes it would overshoot its position and come back,
                        and
                        sometimes it wouldn't. Depending on whether or not the robot overshot or not, it would approach
                        the
                        setpoint from two different sides, and this would affect whether the robot's final angle for
                        that
                        sample was an overshoot or undershoot. I could trust that my ToF sensors were accurate, but
                        my mapping data was still a little noisy. I'm pretty sure this was because of my ability to
                        track
                        angle setpoints with the PD controller, and if I built a better controller, I think I would be
                        able
                        to get more consistent localization results. Overall though, I'm really happy with how well some
                        of my
                        samples turned out, and I'm looking forward to putting all of this control together in Lab 12.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer-->
    <footer class="py-5 bg-dark">
        <div class="container">
            <p class="m-0 text-center text-white">Copyright &copy; Kelvin Resch 2025</p>
        </div>
    </footer>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>